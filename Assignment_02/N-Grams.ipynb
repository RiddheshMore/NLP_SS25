{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d6c338ce2c1b305f1ee56312dc130b13",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h1>Natural Language Processing</h1>\n",
    "    Assignment 02\n",
    "    <h3>General Information:</h3>\n",
    "    <p>Please do not add or delete any cells. Answers belong into the corresponding cells (below the question). If a function is given (either as a signature or a full function), you should not change the name, arguments or return value of the function.<br><br> If you encounter empty cells underneath the answer that can not be edited, please ignore them, they are for testing purposes.<br><br>When editing an assignment there can be the case that there are variables in the kernel. To make sure your assignment works, please restart the kernel and run all cells before submitting (e.g. via <i>Kernel -> Restart & Run All</i>).</p>\n",
    "    <p>Code cells where you are supposed to give your answer often include the line  ```raise NotImplementedError```. This makes it easier to automatically grade answers. If you edit the cell please outcomment or delete this line.</p>\n",
    "    <h3>Submission:</h3>\n",
    "    <p>Please submit your notebook via the web interface (in the main view -> Assignments -> Submit). The assignments are due on <b>Monday at 15:00</b>.</p>\n",
    "    <h3>Group Work:</h3>\n",
    "    <p>You are allowed to work in groups of up to three people. Please enter the UID (your username here) of each member of the group into the next cell. We apply plagiarism checking, so do not submit solutions from other people except your team members. If an assignment has a copied solution, the task will be graded with 0 points for all people with the same solution.</p>\n",
    "    <h3>Questions about the Assignment:</h3>\n",
    "    <p>If you have questions about the assignment please post them in the LEA forum before the deadline. Don't wait until the last day to post questions.</p>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:28:37.243701Z",
     "start_time": "2024-04-30T13:28:37.234226Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Group Work:\n",
    "Enter the UID of each team member into the variables. This is your **LEA username**!\n",
    "If you work alone please leave the second variable empty.\n",
    "'''\n",
    "member1 = ''\n",
    "member2 = ''\n",
    "member3 = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f5db2e86a37d4e3e50cd303dd483f77",
     "grade": false,
     "grade_id": "bigram_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Bigram Language Model\n",
    "\n",
    "We want to build a count based bigram language model based on movie scripts.\n",
    "\n",
    "In the next cell the movie scripts are read into the variables ```sents``` and ```words``` for the movies *Iron Man 2*, *Iron Man 3*, *Spider-Man Homecoming*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T10:05:58.798646Z",
     "start_time": "2024-05-02T10:05:58.753730Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_data(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        sents = pickle.loads(f.read())\n",
    "        words = [word for sent in sents for word in sent]\n",
    "    return sents, words\n",
    "\n",
    "iron_man2_sents, iron_man2_words = load_data(\"/srv/shares/NLP/datasets/marvel/iron_man_2.pkl\")\n",
    "iron_man3_sents, iron_man3_words = load_data(\"/srv/shares/NLP/datasets/marvel/iron_man_3.pkl\")\n",
    "spider_man_sents, spider_man_words = load_data(\"/srv/shares/NLP/datasets/marvel/spider_man_homecoming.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:28:37.381595Z",
     "start_time": "2024-04-30T13:28:37.355312Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "glob.glob(\"/srv/shares/NLP/datasets/marvel/*.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ed78d426418122babcf9c6ee5ae74e0",
     "grade": false,
     "grade_id": "statistics_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.1) Statistics [4 Points]\n",
    "\n",
    "Please calculate the number of types and tokens for the movie *Spider-Man* and save the values in the variables ```types``` and ```tokens```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:28:37.435171Z",
     "start_time": "2024-04-30T13:28:37.387104Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00f6200c700abea9ba70d9b5a1eac9a4",
     "grade": false,
     "grade_id": "statistics",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "types = 0\n",
    "tokens = 0\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print('The script for Spider-Man Homecoming consists of {} tokens and {} types.'.format(\n",
    "    tokens,\n",
    "    types\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:28:37.507563Z",
     "start_time": "2024-04-30T13:28:37.438197Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff42cdad3a3f034939a5d099689b57b2",
     "grade": true,
     "grade_id": "test_statistics",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell, please ignore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a38b6c5f76f5934e87f58860b22f707b",
     "grade": false,
     "grade_id": "heaps_law_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.2) Heap's Law\n",
    "\n",
    "Let us validate Heap's law from the first chapter we read:\n",
    "\n",
    "$|V| = k * N^{\\beta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0d4905af8fd0feddbfe9e38347423942",
     "grade": false,
     "grade_id": "heaps_law_empirical_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2.1) Empirical Study [8 Points]\n",
    "\n",
    "We first want to plot the relationship between types and tokens for the script *Spider-Man Homecoming*.\n",
    "\n",
    "For this you should fill the lists ```number_of_types``` and ```number_of_tokens``` with the corresponding values.\n",
    "\n",
    "So we want to investigate how many types we have after 1 token, 2 tokens, 3 tokens until we have read all the words from the book.\n",
    "\n",
    "*Example:*\n",
    "\n",
    "- ```number_of_tokens```: ```[1, 2, 3, ..., 16, 17, 18, ...]```\n",
    "- ```number_of_types```:  ```[1, 2, 3, ..., 13, 14, 14, ...]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:28:37.570198Z",
     "start_time": "2024-04-30T13:28:37.509903Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76b886d6a7d0ff2914a6e118c0c23d6c",
     "grade": false,
     "grade_id": "heaps_law_empirical",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "number_of_tokens = []\n",
    "number_of_types = []\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "for i in [10, 100, 1000, 10000]:\n",
    "    print('After reading {} tokens we found {} types.'.format(\n",
    "        number_of_tokens[i - 1], number_of_types[i - 1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:48:51.481953Z",
     "start_time": "2024-04-30T13:48:51.430121Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc442d413414a0c98a72f2adaf15cdac",
     "grade": true,
     "grade_id": "test_heaps_law_empirical",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "452dabe6f7c6740e5c63baad28beb395",
     "grade": false,
     "grade_id": "empirical_plot_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2.2) Plot [10 Points]\n",
    "\n",
    "Please plot your findings:\n",
    "\n",
    "- x-Axis: Number of tokens\n",
    "- y-Axis: Number of types\n",
    "\n",
    "Make sure your plot has a grid, a legend, a title and x- and y-label.\n",
    "\n",
    "Add the values for the three movies **Iron Man 2** and **Iron Man 3** to the plot as a single point (total number of tokens, total number of types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:28:38.682591Z",
     "start_time": "2024-04-30T13:28:37.672701Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aac334850ad80fff09b416a81925f679",
     "grade": true,
     "grade_id": "empirical_plot",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea7e0fd5e2e6f82c053a9a087f2c6f95",
     "grade": false,
     "grade_id": "parameter_estimation_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2.3) Estimate parameters $k$ and $\\beta$ [8 points]\n",
    "\n",
    "We want to estimate the parameters $k$ and $\\beta$ for Heap's law based on our movie.\n",
    "\n",
    "Use the function ```curve_fit``` from ```scipy.optimize``` with the previously calculated lists. Save your solution in the variables ```k``` and ```beta```.\n",
    "\n",
    "```curve_fit``` takes in three arguments, the function that relatex x values to y values together with its parameters, the observed x-values and the observed y-values. It return popt (the optimal parameters) and pcov (how well they fit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:28:38.997748Z",
     "start_time": "2024-04-30T13:28:38.684815Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f441ebfd115d535d0d767ea7f418104c",
     "grade": false,
     "grade_id": "parameter_estimation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, k, beta):\n",
    "    return k * x**beta\n",
    "\n",
    "k = 0\n",
    "beta = 0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print('For the movie Spider-Man we estimate k = {:.2f} and beta = {:.2f}'.format(\n",
    "    k,\n",
    "    beta\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:28:39.079127Z",
     "start_time": "2024-04-30T13:28:39.000983Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ecbf5636f4bfc5372a0e559160c3cf9",
     "grade": true,
     "grade_id": "test_parameter_estimation",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0825032e3c73f52d8945040a55c61d8",
     "grade": false,
     "grade_id": "combined_plot_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2.4) Combined plot [10 Points]\n",
    "\n",
    "In our Marvel corpus we have the following movies:\n",
    "\n",
    "- Iron Man 2 \n",
    "- Iron Man 3 \n",
    "- Spider-Man Homecoming \n",
    "\n",
    "Plot the number of types and tokens for each movie as a point (total number of types and tokens) together with the function $|V| = k N^{\\beta}$ with your estimated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:28:39.560011Z",
     "start_time": "2024-04-30T13:28:39.084597Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f19144642b5132172a465fee534b164e",
     "grade": true,
     "grade_id": "combined_plot",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75b30b36d4b76554f1a8c49360f6149e",
     "grade": false,
     "grade_id": "bigram_model_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.1) Bigram Model [50 Points]\n",
    "\n",
    "We now want to build a bigram language model from the movie *Spider-Man Homecoming*.\n",
    "\n",
    "For this you should use the class given in the next cell.\n",
    "\n",
    "1. Read in the sentences from the movie *Spider-Man Homecoming*\n",
    "2. Write a method that returns the unigram count\n",
    "3. Write a method that returns the unigram probability\n",
    "4. Write a method that returns the bigram count\n",
    "5. Write a method that returns the bigram probability\n",
    "6. Write a method that returns the sentence probability based on bigrams\n",
    "\n",
    "*Hints:*\n",
    "\n",
    "- The next cell gives you some inspiration on how to implement the counting of bigrams\n",
    "- Everything should be precomputed in the constructor (```__init__```) and the other functions should not recount anything. If implemented efficiently all the computation will be done in a few seconds (less than 10)!\n",
    "- This class should be **self-contained** and not depend on any code from previous cells!\n",
    "- The ```window``` function is a memory friendly iterator over a list that gives you all n-grams from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:28:39.573443Z",
     "start_time": "2024-04-30T13:28:39.563067Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cd12e6c6e73e0dc28f3bfbb103d7072",
     "grade": false,
     "grade_id": "bigram_model_example",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Example (you do not need to edit this cell):\n",
    "\n",
    "Suppose you have a very small corpus consisting of only the\n",
    "four unique words 'I', 'have', 'a', 'dog' and \n",
    "the sentence start and end markers '<s>' and '</s>'\n",
    "\n",
    "The corpus has the three sentences\n",
    "- <s> I have a dog </s>\n",
    "- <s> a dog I have </s>\n",
    "- <s> a dog </s>\n",
    "'''\n",
    "import numpy as np\n",
    "\n",
    "# First we define the index for each word (the order does not matter)\n",
    "index = {\n",
    "    'I': 0,\n",
    "    'have': 1,\n",
    "    'a': 2,\n",
    "    'dog': 3,\n",
    "    '<s>': 4,\n",
    "    '</s>': 5\n",
    "}\n",
    "\n",
    "# These are our bigrams from the sentences\n",
    "bigrams = [('<s>', 'I'), ('I', 'have'), ('have', 'a'), ('a', 'dog'), ('dog', '</s>'),\n",
    "           ('</s>', '<s>'), ('<s>', 'a'), ('a', 'dog'), ('dog', 'I'), ('I', 'have'), ('have', '</s>'),\n",
    "           ('</s>', '<s>'), ('<s>', 'a'), ('a', 'dog'), ('dog', '</s>')]\n",
    "\n",
    "# Next we create a matrix for the bigram counts,\n",
    "# each entry is a 16 Bit unsigned integer (dtype=np.uint16)\n",
    "counts = np.zeros((len(index), len(index)), dtype=np.uint16)\n",
    "\n",
    "# Fill it with the counts\n",
    "for bigram in bigrams:\n",
    "    index_first_word = index[bigram[0]]\n",
    "    index_second_word = index[bigram[1]]\n",
    "    counts[index_first_word, index_second_word] += 1\n",
    "    \n",
    "# Print out count matrix\n",
    "print(counts)\n",
    "\n",
    "# Check the count for the bigram ('I', 'have'):\n",
    "print('The bigram (\"I\", \"have\") exists {} times.'.format(\n",
    "    counts[index['I'], index['have']]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T10:06:08.867122Z",
     "start_time": "2024-05-02T10:06:07.552846Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c10c015e9201dc1484e029694a3d62d2",
     "grade": false,
     "grade_id": "bigram_model",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "class BigramModel:\n",
    "    \n",
    "    def __init__(self, sentences: List[List[str]]):\n",
    "        '''\n",
    "        Takes in a list of sentences, where each sentence is a \n",
    "        list of words.\n",
    "        \n",
    "        Arguments:\n",
    "            sentences -- List of lists of words (e.g. [['I', 'have', 'a', 'dog'],\n",
    "                                                       ['a', 'dog', 'I', 'have']])\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def window(self, seq, n=2):\n",
    "        '''\n",
    "        Returns a sliding window (of width n) over data from the iterable\n",
    "        \n",
    "        Arguments:\n",
    "            seq      -- the iterable (e.g. list, set, etc) to run the window over\n",
    "            n        -- the size of the window\n",
    "        Returns:\n",
    "            iterator -- an iterator over the sliding windows\n",
    "            \n",
    "        Usage:\n",
    "            my_list = [1, 2, 3, 4]\n",
    "            for slice in self.window(my_list):\n",
    "                print(slice)\n",
    "                \n",
    "            # Output: (1, 2)\n",
    "                      (2, 3)\n",
    "                      (3, 4)\n",
    "        '''\n",
    "        \"Returns a sliding window (of width n) over data from the iterable\"\n",
    "        \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "        it = iter(seq)\n",
    "        result = tuple(islice(it, n))\n",
    "        if len(result) == n:\n",
    "            yield result\n",
    "        for elem in it:\n",
    "            result = result[1:] + (elem,)\n",
    "            yield result\n",
    "            \n",
    "    def unigram_count(self, word: str) -> int:\n",
    "        '''\n",
    "        Returns the unigram count for the word.\n",
    "        If the word does not exist in our corpus, return 0.\n",
    "        \n",
    "        Arguments:\n",
    "            word  -- word we want to know the count of\n",
    "        Returns:\n",
    "            count -- how often the word appears in the corpus\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def unigram_probability(self, word:str) -> float:\n",
    "        '''\n",
    "        Returns the unigram probability for the word.\n",
    "        If the word does not exist in our corpus, return 0.\n",
    "        \n",
    "        Arguments:\n",
    "            word        -- word we want to know the probability of\n",
    "        Returns:\n",
    "            probability -- how likely it is to choose the word at random\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def bigram_count(self, word1:str, word2:str) -> int:\n",
    "        '''\n",
    "        Returns the bigram count for the word1 followed by word2.\n",
    "        If either of the words does not exist in our corpus, return 0.\n",
    "        \n",
    "        Arguments:\n",
    "            word1  -- first word of the bigram\n",
    "            word2  -- second word of the bigram\n",
    "        Returns:\n",
    "            count  -- how often the bigram appears in the corpus\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def bigram_probability(self, word1:str, word2:str) -> float:\n",
    "        '''\n",
    "        Returns the bigram probability for the word1 followed by word2.\n",
    "        This is the conditional probability P(word2 | word1).\n",
    "        If either of the words does not exist in our corpus, return 0.\n",
    "        \n",
    "        Arguments:\n",
    "            word1       -- first word of the bigram\n",
    "            word2       -- second word of the bigram\n",
    "        Returns:\n",
    "            probability -- how likely it is to choose the word at random\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def sentence_probability(self, sentence:List[str]) -> float:\n",
    "        '''\n",
    "        Return the probability for the given sentence based on our\n",
    "        bigram probabilities\n",
    "        \n",
    "        Arguments:\n",
    "            sentence    -- list of tokens from the sentence \n",
    "                           (e.g. ['<s>', 'I', 'have', 'a', 'dog', '</s>'])\n",
    "        Returns:\n",
    "            probability -- probability of the sentence\n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "          \n",
    "sents, words = load_data(\"/srv/shares/NLP/datasets/marvel/spider_man_homecoming.pkl\")\n",
    "model = BigramModel(sents)\n",
    "\n",
    "# Some prints and tests\n",
    "\n",
    "print('The unigram \"Peter\" appears {} times in the book!'.format(\n",
    "    model.unigram_count('Peter')\n",
    ")) ## Should print 1254\n",
    "\n",
    "print('The probability for the unigram \"Happy\" is {:.4f}.'.format(\n",
    "    model.unigram_probability('Happy')\n",
    ")) ## Should print 0.0026\n",
    "\n",
    "print('The bigram \"I am\" appears {} times in the book!'.format(\n",
    "    model.bigram_count('I', 'am')\n",
    ")) ## Should print 3\n",
    "\n",
    "print('The probability for the bigram \"I have\" is {:.4f}.'.format(\n",
    "    model.bigram_probability('I', 'have')\n",
    ")) ## Should print 0.0233\n",
    "\n",
    "print('The sentence probability for the sentence \"Alien artifacts lie among the rubble.\" is {:.4e}.'.format(\n",
    "    model.sentence_probability(['<s>', 'Alien', 'artifacts', 'lie', 'among', 'the', 'rubble', '.', '</s>'])\n",
    ")) ## Should print 7.2583e-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T10:07:18.865651Z",
     "start_time": "2024-05-02T10:07:18.115976Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd1254e39064ddee3367b44ede3faa74",
     "grade": true,
     "grade_id": "test_bigram_model",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd8dd937749ed32641b672eec799d90b",
     "grade": false,
     "grade_id": "bigram_application_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.2) Using the model [10 Points]\n",
    "\n",
    "With our model we can now answer some questions.\n",
    "\n",
    "1. How often does a certain word appear in the movie?\n",
    "    - Give the number of times the word 'Avengers' appears in the book - Store this in the variable ```count_Avengers```.\n",
    "    - Give the number of times the word 'She' appears in the book - Store this in the variable ```count_She```.\n",
    "2. How many sentences start or end with a certain word or token?\n",
    "    - Give the probability that a sentence starts with the word 'I' - Store this in the variable ```p_sentence_begins_with_I```\n",
    "    - Give the probability that a sentence ends with '!' in contrast to sentences ending in other words - Store this in the variable ```p_sentence_ends_in_exlamation``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:28:41.184702Z",
     "start_time": "2024-04-30T13:28:40.992839Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65828ffed9fd82be49a6d95878a618ee",
     "grade": false,
     "grade_id": "bigram_application",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T13:28:41.391001Z",
     "start_time": "2024-04-30T13:28:41.187025Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "759582645386c7f162a1f53102ce9781",
     "grade": true,
     "grade_id": "test_bigram_application",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell, please ignore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7072dae2ec04a515ff00fc067cd75c95",
     "grade": false,
     "grade_id": "cell-e7b98db0eee3eb8d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Generating Random Sentences\n",
    "\n",
    "You are given the following function that given a model can generate random sentences.\n",
    "\n",
    "You might need to change some lines if your implementation significantly differs from mine, but the idea is to:\n",
    "\n",
    "- Have a reverse index where an id is mapped to a token\n",
    "- Have an index where a token is mapped to an id\n",
    "- Have a bigram_counts matrix\n",
    "\n",
    "Whenever you execute the function it will generate a random sentence. You can also try this with the other movies.\n",
    "\n",
    "**This is not graded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T14:01:57.801280Z",
     "start_time": "2024-04-30T14:01:57.596501Z"
    }
   },
   "outputs": [],
   "source": [
    "import random as rd\n",
    "\n",
    "def generate_random_sentence(model):\n",
    "    start = '<s>'\n",
    "    end = '</s>'\n",
    "\n",
    "\n",
    "    reverse_index = {value: key for key, value in model.index.items()}\n",
    "\n",
    "    sentence = [start]\n",
    "    token = sentence[-1]\n",
    "    while token != end:\n",
    "\n",
    "        index = model.index[token]\n",
    "        row = model.bigram_counts[index, :]\n",
    "        token = rd.choices(range(len(row)), weights=row)[0]\n",
    "        token = reverse_index[token]\n",
    "        sentence.append(token)\n",
    "\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "sentences, _ = load_data(\"/srv/shares/NLP/datasets/marvel/spider_man_homecoming.pkl\")\n",
    "model = BigramModel(sentences)\n",
    "generate_random_sentence(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
